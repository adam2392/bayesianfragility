{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling Excercise\n",
    "\n",
    "7/13/18: Here, I want to walk through an implementation and derivation of a Gibbs sampler for a Bayesian model we want to build.\n",
    "\n",
    "https://kieranrcampbell.github.io/blog/2016/05/15/gibbs-sampling-bayesian-linear-regression.html\n",
    "\n",
    "## Bayesian Linear Regression\n",
    "\n",
    "Here, we have a model we wnat to build of the form\n",
    "$$ y=Wx+b $$, where Y is normally distributed\n",
    "$$ Y \\approx N (\\beta_0 + \\beta_1 x_i, 1/\\gamma$$\n",
    "$$ y=\\beta_0 + \\beta_1 x_i + \\epsilon, \\epsilon \\approx N(0, 1/\\gamma)$$\n",
    "\n",
    "Because we assume normality of the error term, we can write the likelihood of this model given observations $(y_i, x_i), i=1,...,N$. We can place priors on the data that we want to estimate; in this case it is the weight terms and the spread of the error.\n",
    "\n",
    "$$\n",
    "\\beta_0 /~ N(\\mu_0, 1/\\gamma_0) \\\\\n",
    "\\beta_1 /~ N(\\mu_1, 1/\\gamma_1) \\\\\n",
    "\\gamma /~ Gamma(\\alpha, \\beta) \\\\\n",
    "$$\n",
    "\n",
    "Of course, we don't necessarily need to follow these models on the priors, but have \"infinitely\" many choices to choose from. We can guide these prior decisions based on previous knowledge we have about the problem, or choose rather \"uninformative\" priors, by choosing uniform distributions.\n",
    "\n",
    "## Gibbs Sampling\n",
    "The goal of sampling is, given parameters $\\theta_i$, we want to find the posterior distribution $P(\\theta_1, ...,\\theta_m || x)$, the probability distribution of our parameters given data, x. To do this for GIBBS sampling, we need the conditional distributions of each parameter.\n",
    "\n",
    "The algorithms is then as follows:\n",
    "1. Initialize $\\theta_2^{(i)}$.\n",
    "2. For i=1:K \n",
    "    * Sample $\\theta_1^{(i+1)} \\~ p(\\theta_1 || \\theta_2^{(i)}, x$ \n",
    "    * Sample $\\theta_2^{(i+1)} \\~ p(\\theta_2 || \\theta_1^{(i+1)}, x$\n",
    "\n",
    "## Pros/Cons:\n",
    "Pros:\n",
    "* no tuning parameters required, as opposed to Metropolis-Hastings algorithm\n",
    "\n",
    "Cons:\n",
    "* derivation of the conditional distributions is needed, to derive update rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as tt\n",
    "import pymc3 as pm\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# import basic plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "# Import magic commands for jupyter notebook \n",
    "# - autoreloading a module\n",
    "# - profiling functions for memory usage and scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "1. What happens when we do not have conjugate priors? Does the method still work?\n",
    "2. Are we always able to derive some conditional distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fragility3",
   "language": "python",
   "name": "fragility3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
